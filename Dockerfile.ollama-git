FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

# Install dependencies
RUN apt-get update && apt-get install -y \
    python3.11 python3.11-venv python3-pip \
    git curl wget sudo nano vim \
    fish zsh fontconfig locales \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Setup locale
RUN locale-gen en_US.UTF-8
ENV LANG=en_US.UTF-8 LANGUAGE=en_US:en LC_ALL=en_US.UTF-8

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Install Ollama
RUN curl -fsSL https://ollama.ai/install.sh | sh || true

# Ensure ollama user exists with proper setup
RUN useradd -m -s /bin/bash ollama 2>/dev/null || true && \
    echo "ollama ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

# Install oh-my-posh
RUN wget https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest/download/posh-linux-amd64 -O /usr/local/bin/oh-my-posh && \
    chmod +x /usr/local/bin/oh-my-posh

# Create directories before switching user
RUN mkdir -p /home/ollama/.ollama/logs /home/ollama/workspace && \
    chown -R ollama:ollama /home/ollama

USER ollama
WORKDIR /home/ollama

# Configure shells with atomic theme
RUN echo 'eval "$(oh-my-posh init bash --config https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/atomic.omp.json)"' >> ~/.bashrc && \
    echo 'alias ll="ls -la"' >> ~/.bashrc && \
    echo 'alias oc="cd /home/ollama/ollama-code && source venv/bin/activate && python -m ollama_code.cli"' >> ~/.bashrc

# Clone and setup ollama-code (use ADD to force fresh clone)
# The date comment forces Docker to not use cache for this layer
ADD https://api.github.com/repos/seanpoyner/ollama-code/git/refs/heads/main version.json
RUN git clone https://github.com/seanpoyner/ollama-code.git && \
    cd ollama-code && \
    python3 -m venv venv && \
    . venv/bin/activate && \
    pip install --upgrade pip && \
    pip install -e .

# Create simple launcher
RUN echo '#!/bin/bash\n# Preserve the current working directory\nexport OLLAMA_CODE_USER_CWD="$PWD"\ncd /home/ollama/ollama-code\nsource venv/bin/activate\nexport PYTHONPATH=/home/ollama/ollama-code:$PYTHONPATH\npython -m ollama_code.cli "$@"' > ~/ollama-code.sh && \
    chmod +x ~/ollama-code.sh && \
    sudo ln -sf /home/ollama/ollama-code.sh /usr/local/bin/ollama-code

# Create startup script that pulls models
RUN echo '#!/bin/bash\n\
echo "ðŸ³ Ollama Code Docker Environment (Atomic Theme)"\n\
echo ""\n\
echo "Starting Ollama server..."\n\
ollama serve > ~/.ollama/logs/ollama.log 2>&1 &\n\
OLLAMA_PID=$!\n\
\n\
# Wait for Ollama to start\n\
echo "Waiting for Ollama to start..."\n\
for i in {1..30}; do\n\
    if curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then\n\
        echo "âœ… Ollama server started successfully"\n\
        break\n\
    fi\n\
    sleep 1\n\
done\n\
\n\
# Check if models need to be pulled\n\
echo ""\n\
echo "Checking for required models..."\n\
\n\
# Function to check and pull model\n\
check_and_pull_model() {\n\
    local model=$1\n\
    if ! ollama list | grep -q "^$model"; then\n\
        echo "ðŸ“¥ Pulling $model..."\n\
        ollama pull $model\n\
        if [ $? -eq 0 ]; then\n\
            echo "âœ… Successfully pulled $model"\n\
        else\n\
            echo "âŒ Failed to pull $model"\n\
        fi\n\
    else\n\
        echo "âœ… $model already available"\n\
    fi\n\
}\n\
\n\
# Pull required models\n\
check_and_pull_model "llama3.2:3b"\n\
check_and_pull_model "qwen2.5:0.5b"\n\
check_and_pull_model "qwen2.5-coder:7b"\n\
check_and_pull_model "nomic-embed-text"\n\
\n\
echo ""\n\
echo "âœ¨ All models pulled successfully!"\n\
echo ""\n\
echo "Available models:"\n\
ollama list\n\
echo ""\n\
echo "ðŸš€ Ready! Run: ollama-code"\n\
echo ""\n\
echo "ðŸ“ Note: First startup pulls models and may take several minutes."\n\
echo "    Subsequent startups will be much faster."\n\
echo ""\n\
\n\
# Keep container running\n\
tail -f /dev/null' > ~/start.sh && \
    chmod +x ~/start.sh

WORKDIR /home/ollama/workspace
ENTRYPOINT ["/home/ollama/start.sh"]