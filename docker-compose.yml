version: '3.8'

services:
  ollama-code:
    build: .
    image: ollama-code:latest
    container_name: ollama-code-test
    hostname: ollama-code
    
    # Interactive terminal
    stdin_open: true
    tty: true
    
    # Environment variables
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=http://localhost:11434
      # Add your GitHub token here or pass via .env file
      # - GITHUB_PERSONAL_ACCESS_TOKEN=your_token_here
    
    # Volumes for persistence
    volumes:
      # Workspace for testing
      - ./workspace:/home/ollama/workspace
      # Ollama models (shared with host if needed)
      - ollama-models:/home/ollama/.ollama/models
      # Ollama code config
      - ollama-config:/home/ollama/.ollama/ollama-code
      # Conversation history
      - ./ollama-code/.ollama-code:/home/ollama/workspace/.ollama-code
    
    # Network settings
    network_mode: host
    
    # Security options
    security_opt:
      - no-new-privileges:true
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

volumes:
  ollama-models:
  ollama-config: